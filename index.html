
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Explore-Stop">
    <meta name="keywords" content="Exploration Stopping Criterion, Area Estimate, Robot Exploration, Mapping">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Estimating Map Completeness in Robot Exploration </title>



    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro|Crimson+Text"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/HoloDeckLogo.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>


    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4K952PNF1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4K952PNF1');
</script>

</head>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">
                        <!--<span class="house-svg"></span>-->
                        Estimating Map Completeness in Robot Exploration
                    </h1>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="http://luperto.di.unimi.it">Matteo Luperto</a>,
            </span>
            <span class="author-block">
              Marco Maria Ferrara,
            </span>
                        <span class="author-block">
              <a href="https://boracchi.faculty.polimi.it">Giacomo Boracchi</a>,
            </span>
                        <span class="author-block">
              <a href="https://amigoni.faculty.polimi.it/">Francesco Amigoni</a>
            </span>

                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">ML is with the Department of Computer Science, University of
                        Milan, Milano, Italy.
                        <br />
                        MF, GB, and FA are with the Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy.</span>
                    </span>&nbsp;&nbsp;

                    </div>

                    <div class="is-size-5 emails">
            <span class="emails">
              Corresponding author:<a>matteo.luperto@unimi.it</a>&nbsp;&nbsp;
            </span>

                    </div>

                    <!-- </div> -->
                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->

                            <!-- arxiv Link. -->
                <span class="link-block">
                    <a href="https://arxiv.org/abs/2406.13482"
                        class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/aislabunimi/exploration-aware"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
                            <!-- Email Link. -->

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section", id="intro">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="columns">
                <div class="column is-half">
                    <img src="static/images/office1.png">
                    <p style="font-size: 0.8em">t = 90 min.</p>
                </div>
                <div class="column is-half">
                    <img src="static/images/office2.png" >
                    <p style="font-size: 0.8em">T = 150 min</p>
                </div>
            </div>
        </div>

        <div class="content has-text-justified">
            <p>
                The map after t = 90 min of exploration (left) already represents almost all of the environment (the 98% of the mapped area explored), except a few uninteresting corners and portions of rooms scattered across the whole environment, highlighted in blue. This exploration run ends at T = 150 min (right image) when all frontiers have been visited. During the time interval, the robot moves back and forth to explore the remaining frontiers, possibly jeopardizing the whole mapping process. 
                Our method infers that the map at the right is almost fully explored and stops the exploration, reducing the total exploration time.
            </p>
        </div>
        <!--/ Abstract. -->
    </div>
</section>

<section class="section", id="abstract">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-five-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        We propose a method that, given a partial grid map of an indoor environment built by an autonomous mobile robot, estimates the amount of the explored area represented in the map, as well as whether the uncovered part is still worth being explored or not. Our method is based on a deep convolutional neural network trained on data from partially explored environments with annotations derived from the knowledge of the entire map (which is not available when the network is used for inference). We show how such a network can be used to define a stopping criterion to terminate the exploration process when it is no longer adding relevant details about the environment to the map, saving, on average, 40% of the total exploration time with respect to covering all the area of the environment.                </div>
            </div>
        </div>
    </div>
</section>

<section class="section", id="scenario">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-five-fifths">
                <h2 class="title is-3">Scenario</h2>
                <div class="content has-text-justified">
                    <p>

                        We consider an autonomous mobile robot that is exploring an unseen environment in order to obtain a full map of it. 
                        The robot is equipped with a 2D laser scanner, and it is able to build a partial grid map of the environment as it moves around.
                        While several exploration strategy have been proposed to guide the robot in the environment, the robot should also know when to stop the exploration process.
                        A method that decides when an exploration process should stop is called a stopping criterion.
                        The importance of having a good stopping criterion is paramount. Indeed, the later stages of a typical exploration process often provide little contribution, and they can cause a degradation of the mapping performance, leading to map inconsistencies and unrecoverable states that invalidate the entire mapping process. 
                    </p>
                </div>

            </div>
        </div>
        <!--/ Abstract. -->
    </div>
</section>

<section class="section", id="Method">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-five-fifths">
                <h2 class="title is-3">Method</h2>
                <div class="content has-text-justified">
                <p>
                    We evaluate the partial map of an environment and estimates the advancement of the exploration process. Our method processes partial 2D grid maps obtained during exploration as images, using a Convolutional Neural Network (CNN). We exploit the fact that assessing the degree of completeness of a map is a task well suited for CNNs, as maps of indoor environments exhibit very peculiar patterns that allow humans to correctly assess – in most cases – whether there is still some potentially
                    large area to explore or not.
                    More precisely, we:
                    <ul>
                    <li> define a stopping criterion that determines whether a partial map under scrutiny can be considered as enough explored or not,</li>
                    <li> estimate the status of the exploration process as the percentage of the total area explored by the robot (with- out needing the knowledge of the whole environment), and</li>
                    <li>identify the areas of the map that are of interest (if any) to progress the exploration.</li>
                    </ul>
                </p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->
    </div>
</section>

<section class="section" id="architecture">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-five-fifths">
                <h2 class="title is-3">Models</h2>
                <div class="content has-text-justified">
                    <p>
                        Our main intuition consists in casting the assessment of the status of the exploration in a visual recognition problem.
                        We train a deep convolutional neural network for each of the tasks of stopping the exploration run and estimate the percentage of the explored area. 
                        The stopping criterion is modeled as a visual recognition problem where the classification task is to distinguish between maps that are not-explored yet from those that are sufficiently explored. 
                        The first class contains maps that a human (who knows the full map of the environment) would consider still to be explored, typically because of missing areas that are of interest like one or more rooms that have not been mapped. 
                        The second class contains maps that a human would consider complete enough to represent the full environment. In this second case, some small parts of the environments (like corners) may not be entirely mapped yet, but such parts are not so relevant. 
                        The second task, which is estimating the portion of the area already explored, is modeled as a regression problem using the CNN backbone adopted for solving the first task.
                        For both tasks we rely on a EfficientNet B1 architecture, pre-trained on ImageNet, and fine-tuned on our dataset.
                    </p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->
    </div>
</section>

<section class="section" id="experiments">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-five-fifths">
                <h2 class="title is-3">Experimental results</h2>


                <div class="content has-text-justified">
                    <p>
                        Our method is tested both online and offline by considering an extensive set of thousands of maps as acquired during exploration runs by an autonomoous robot.
                        We show that our method is able to correctly estimate the percentage of the explored area and to stop the exploration process when the map is almost fully explored.
                        Our method is able to save, on average, 40% of the total exploration time with respect to covering all the area of the environment.
                        The DNN model is able to distinguish between fully-explored and partially-explored maps with an accuracy above 90%. 
                        Interestingly, we can keep the rate of false positives (i.e., maps that are considered fully explored but are not) below 2%.
                    </p>
                </div>
                <div class="content is-centered">
                    <img src="static/images/incremental.png" style="width: 80%">
                </div>

                <div class="content has-text-justified">
                    <p>
                        The example image shows our method applied to partial maps obtained after 10, 20, 30, and 40 minutes of exploration of two environments. In the environment in the first row (a)-(d), the exploration ends after T = 70 min; with our method, we can reduce such time by 30 minutes (d). In the environment in the second row (e)-(h), the exploration is concluded after T = 90 min; we reduce such time by 50 minutes (h). The areas highlighted in the partial maps are the locations that the neural network of our method identifies as relevant to make its prediction (red and blue denotes the most and the least relevant regions, respectively).
                    </p>
                </div>
                <div class="content is-centered">
                    <img src="static/images/area.png" style="width: 40%">
                </div>

                <div class="content has-text-justified">
                    <p>
                        Overall, can estimate the percentage of the explored area with an error of just 4.68%, which is low and stable across all 15 test environments. 
                        The figure above shows how the average error of estimating the percentage of the area progresses during exploration runs. While at the beginning of the exploration, the error is higher (as the portion of the map known to the robot is too little to make an accurate estimation), the error becomes stable and under 10% when half or more of the environment is explored. 
                        Overall, our method can provide a reliable estimate of the amount of the explored area represented in a map.
                    </p>
                </div>
                <div class="content is-centered">
                    <img src="static/images/real.png" style="width: 80%">
                </div>

                <div class="content has-text-justified">
                    <p>
                        Finally, we tested our method on real data collected by an autonomous robot.
                        Despite this domain shift, our model shows robust performance by correctly classifying all the maps as not-explored. 
                        This result is particularly relevant as it shows the genralization of our results to real-world settings.
                     </p>
                </div>
            
        </div>
        <!--/ Abstract. -->
    </div>
</section>









<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title is-3">BibTeX</h2>
        <pre style="font-size: 16px;"><code>@misc{exploreawareness,
      title={Estimating Map Completeness in Robot Exploration},
      author={Matteo Luperto and Marco Maria Ferrara and Giacomo Boracchi and Francesco Amigoni},
      year={2024}
}</code></pre>
    </div>
</section>

<footer class="footer">
    <div class="container">
        <div class="content has-text-centered">

            <a class="icon-link" href="https://arxiv.org/abs/2406.13482" class="external-link" disabled>
                <i class="ai ai-arxiv"></i>
            </a>
            <a class="icon-link" href="https://github.com/aislabunimi/exploration-aware" class="external-link" disabled>
                <i class="fab fa-github"></i>
            </a>

        </div>
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content", style="text-align: center;">
                    <p>
                        This website was developed by referencing <a href="https://yueyang1996.github.io/holodeck/">this</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
